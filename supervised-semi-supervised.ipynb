{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldkrZD9CLQg1",
        "outputId": "7926ac9b-0b52-4698-9560-15f44f8fd5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Path to dataset\n",
        "dataset_dir = './drive/MyDrive/thesis/kaggle-dataset'\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image_path, img_size=(128, 128)):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img_to_array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "# Load dataset\n",
        "def load_dataset(dataset_dir, img_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(dataset_dir))\n",
        "\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                image_path = os.path.join(class_dir, image_name)\n",
        "                img = preprocess_image(image_path, img_size)\n",
        "                images.append(img)\n",
        "                labels.append(class_idx)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels, class_names\n",
        "\n",
        "# Load and split dataset\n",
        "images, labels, class_names = load_dataset(dataset_dir)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "TzG_V2ANLezp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Build CNN model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(class_names)\n",
        "\n",
        "cnn_model = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Train CNN model\n",
        "cnn_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnW40MSDLusv",
        "outputId": "d3340034-f584-4dc5-b288-e1213a0e7b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 937ms/step - accuracy: 0.3366 - loss: 1.8237 - val_accuracy: 0.5128 - val_loss: 1.1520\n",
            "Epoch 2/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 940ms/step - accuracy: 0.5349 - loss: 1.1136 - val_accuracy: 0.6694 - val_loss: 0.8894\n",
            "Epoch 3/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 928ms/step - accuracy: 0.6664 - loss: 0.8313 - val_accuracy: 0.7428 - val_loss: 0.7255\n",
            "Epoch 4/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 890ms/step - accuracy: 0.7805 - loss: 0.6146 - val_accuracy: 0.7766 - val_loss: 0.6276\n",
            "Epoch 5/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 913ms/step - accuracy: 0.8350 - loss: 0.4554 - val_accuracy: 0.8038 - val_loss: 0.5919\n",
            "Epoch 6/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 921ms/step - accuracy: 0.8834 - loss: 0.3229 - val_accuracy: 0.7906 - val_loss: 0.5928\n",
            "Epoch 7/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 935ms/step - accuracy: 0.9108 - loss: 0.2503 - val_accuracy: 0.8483 - val_loss: 0.5184\n",
            "Epoch 8/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 903ms/step - accuracy: 0.9389 - loss: 0.1848 - val_accuracy: 0.8566 - val_loss: 0.5603\n",
            "Epoch 9/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 904ms/step - accuracy: 0.9527 - loss: 0.1404 - val_accuracy: 0.7997 - val_loss: 0.7644\n",
            "Epoch 10/10\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 913ms/step - accuracy: 0.9523 - loss: 0.1305 - val_accuracy: 0.8450 - val_loss: 0.6316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7c6bfa4e20>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Example of using SVM with self-training\n",
        "def semi_supervised_learning(X_train, y_train, X_unlabeled):\n",
        "    # Convert one-hot labels to integer class labels\n",
        "    y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "    # SVM for supervised learning\n",
        "    base_model = SVC(probability=True)\n",
        "\n",
        "    # Self-Training Classifier\n",
        "    self_training_model = SelfTrainingClassifier(base_model)\n",
        "\n",
        "    # Train with labeled data\n",
        "    self_training_model.fit(X_train.reshape(X_train.shape[0], -1), y_train_int)\n",
        "\n",
        "    # Predict on unlabeled data and fine-tune\n",
        "    pseudo_labels = self_training_model.predict(X_unlabeled.reshape(X_unlabeled.shape[0], -1))\n",
        "\n",
        "    # Optionally, combine pseudo-labeled data with labeled data and retrain\n",
        "    return pseudo_labels\n",
        "\n",
        "# Assume X_unlabeled contains unlabeled data\n",
        "pseudo_labels = semi_supervised_learning(X_train, y_train, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X17zuQ2TL1Y1",
        "outputId": "6eba1296-3811-4534-b3dd-ab4c99625000"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/semi_supervised/_self_training.py:227: UserWarning: y contains no unlabeled samples\n",
            "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Supervised model evaluation\n",
        "y_pred_supervised = cnn_model.predict(X_test)\n",
        "print(\"Supervised Model Classification Report:\")\n",
        "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred_supervised, axis=1)))\n",
        "\n",
        "# Semi-supervised model evaluation\n",
        "print(\"Semi-Supervised Model Classification Report:\")\n",
        "print(confusion_matrix(np.argmax(y_test, axis=1), pseudo_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hie4xUt0L2vd",
        "outputId": "182faa80-2418-4a98-84cf-8c414a4cba2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 281ms/step\n",
            "Supervised Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.77      0.81       210\n",
            "           1       0.85      0.87      0.86       365\n",
            "           2       0.92      0.75      0.83       296\n",
            "           3       0.78      0.95      0.86       342\n",
            "\n",
            "    accuracy                           0.85      1213\n",
            "   macro avg       0.86      0.83      0.84      1213\n",
            "weighted avg       0.85      0.85      0.84      1213\n",
            "\n",
            "Semi-Supervised Model Classification Report:\n",
            "[[104  28  29  49]\n",
            " [  4 297  31  33]\n",
            " [  6  55 207  28]\n",
            " [  5  33  17 287]]\n"
          ]
        }
      ]
    }
  ]
}